{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56dbdf7-b450-4e6c-a8c3-e13acf994e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(\"..\")  # Adjust if necessary\n",
    "\n",
    "# Add to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6272cdf7-f218-406a-8ac9-84774364b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cesarlindberg/anaconda3/envs/cardiac_pinn/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3637c114-a226-40d3-baec-d28cdae383bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8bd2ec-0ab1-4c8d-9014-0fca5c8a2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1dc0269-470c-4b2e-9f13-b615abff95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 0) Imports & Setup\n",
    "# ---------------------------------------------\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from src.training.pinnex_data_loader import get_dataloaders\n",
    "from src.networks.pinnex_models import PINNWithECG\n",
    "from src.networks.pinn_wrapper import CachedPINNWrapper\n",
    "from src.training.trainer_pinnex import train_pinnex_minibatch_with_ecg\n",
    "from src.utils.evaluation import evaluate_pinnex, compute_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12cf1aa3-d0f2-41ed-bb46-3c4044cc81ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 1) Load and Inspect Data\n",
    "# ---------------------------------------------\n",
    "\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-7\n",
    "physics_weight = 0\n",
    "batch_size = 1\n",
    "batches_per_epoch = 1\n",
    "phys_batch_size = 2048\n",
    "val_ratio = 0.15\n",
    "val_every_n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5223e1c6-c1b3-4785-8f5e-a555cea1aa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting by base_sim_id (delay variant grouping active, using seed 41).\n",
      "Total unique base_sim_ids: 1605\n",
      "Number of base_sim_ids for validation: 240\n",
      "Validation base_sim_ids: [1275, 3122, 3307, 3471, 3656, 1387, 3628, 3589, 3501, 2056, 3042, 2152, 2333, 1305, 3757, 3702, 3562, 3638, 2112, 2372, 3418, 1062, 1029, 3530, 3616, 3576, 3124, 1070, 3389, 3217, 1313, 1399, 2096, 3099, 1016, 2110, 3113, 3594, 2111, 2072, 1082, 1243, 3679, 1036, 3597, 3773, 2241, 3568, 3143, 1318, 2291, 2377, 3467, 3382, 3249, 2084, 3344, 2182, 3516, 1126, 3427, 2192, 3136, 3555, 1250, 1391, 1237, 2, 2030, 3480, 3227, 3432, 3318, 1106, 2346, 3563, 3436, 3173, 2296, 3512, 3689, 2183, 2059, 2209, 1356, 3091, 2118, 1225, 2344, 3272, 1028, 3699, 3192, 3132, 2237, 3410, 3654, 3089, 3170, 3041, 3722, 3315, 1229, 3345, 1280, 1133, 2128, 1370, 3473, 1165, 2073, 2369, 1219, 3466, 3715, 2136, 3479, 1101, 1375, 2113, 2232, 1161, 3513, 3564, 1079, 3711, 1241, 2225, 3670, 3152, 2394, 1096, 3015, 3578, 2023, 2278, 3788, 1152, 2257, 2082, 1287, 2338, 2309, 2391, 1334, 2196, 1027, 1294, 1153, 3643, 3746, 1360, 3464, 3243, 1306, 2222, 1193, 2249, 2199, 3296, 3198, 1170, 3622, 3116, 2143, 2317, 3095, 3371, 2339, 3585, 3613, 2335, 2171, 1068, 3259, 3312, 2020, 1042, 3193, 1339, 1367, 1288, 2198, 3081, 3354, 2009, 3602, 3341, 3147, 3050, 3067, 1290, 3496, 2076, 2081, 3476, 3411, 3688, 2264, 3098, 3514, 2012, 2269, 3005, 2306, 3577, 1255, 3246, 1362, 2341, 3493, 2326, 1023, 1131, 3792, 3208, 3094, 1086, 1041, 2214, 1084, 3231, 2283, 3701, 1369, 3574, 3109, 3437, 1355, 3717, 3104, 2181, 3720, 2284, 1340, 1046, 2124, 3460, 3687, 1347]\n",
      "Split by base_sim_id: 33213385 train rows (from 5460 unique sim_ids), 5841387 val rows (from 960 unique sim_ids).\n",
      "Warning: 'cv' column not found in df_spatial. Using 0 as a placeholder for V.\n",
      "Warning: 'cv' column not found in df_spatial. Using 0 as a placeholder for V.\n"
     ]
    }
   ],
   "source": [
    "# Paths for spatiotemporal and ECG data\n",
    "spatiotemp_path = \"../data/synthetic/parsed/activation_heart_123fib.parquet\"\n",
    "ecg_path = \"../data/synthetic/parsed/ecg_heart_123fib.parquet\"\n",
    "\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    spatiotemp_path=spatiotemp_path,\n",
    "    ecg_path=ecg_path,\n",
    "    batch_size=batch_size,\n",
    "    val_ratio=val_ratio,\n",
    "    seed=41,\n",
    "    group_by_delay_variant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8bc4ef-3f4b-49ff-b301-85cc68bb2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"v_max\": 810, \"t_scale\": 215, \"l_scale\": 50000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dbe3241-d9f8-4931-b6bd-78d13bb3624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default desired_channels_per_block: [16, 32, 64, 128] for n_blocks=4\n",
      "Using default desired_channels_per_block: [16, 32, 64, 128] for n_blocks=4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "base_model = PINNWithECG(\n",
    "    params,  # your existing params dictionary\n",
    "    pde_latent_dim=64,\n",
    "    ecg_latent_dim=64,  # Can be 64 if you want it smaller than pde_latent_dim for gated\n",
    "    pde_hidden_architecture=[64, 128, 128], # Input 51 -> 128 -> 256 -> 256 (then final map to pde_latent_dim)\n",
    "    ecg_hidden_architecture=[256, 128], # FC layers after CNN, input ~3328 (from 256 channels * 13 seq_len) -> 512 -> 256 (then final map to ecg_latent_dim)\n",
    "    decoder_hidden_architecture=[128, 64, 32], # Input pde_latent_dim (128) -> 256 -> 128 -> 64 (then final map to 2 outputs)\n",
    "    n_leads=12,\n",
    "    seq_len=201,\n",
    "    fusion_mode=\"mul\", # CHANGED based on your text's findings\n",
    "    n_blocks=4  # Number of CNN blocks in ECG_Encoder\n",
    ")\n",
    "\n",
    "\n",
    "base_model = PINNWithECG(\n",
    "    params,\n",
    "    pde_latent_dim=15,      # adjust as needed\n",
    "    ecg_latent_dim=15,\n",
    "    pde_hidden_architecture=[15, 15, 15, 15, 15, 15, 15],  # Example hidden layer sizes for PDE encoder\n",
    "    ecg_hidden_architecture=[128, 64],  # Example hidden layer sizes for ECG encoder (FC part)\n",
    "    decoder_hidden_architecture=[32, 32],  # Example hidden layer sizes for decoder\n",
    "    n_leads=12,\n",
    "    seq_len=201,\n",
    "    fusion_mode=\"mul\",\n",
    "    n_blocks=4\n",
    ")\n",
    "\n",
    "#base_model.load_state_dict(torch.load(\"models/heart3fibTEST.pth\"))\n",
    "#checkpoint = torch.load(\"models/heart_123fib_phys.pth\", map_location=torch.device('cuda'))\n",
    "\n",
    "if False: # Your existing conditional block\n",
    "    component_names = [\"pde_encoder\", \"ecg_encoder\", \"decoder_body\", \"decoder_out\"]\n",
    "\n",
    "    for name in component_names:\n",
    "        prefix = f\"{name}.\"\n",
    "        weights = {k.replace(prefix, \"\"): v for k, v in checkpoint.items() if k.startswith(prefix)}\n",
    "        \n",
    "        if weights:\n",
    "            try:\n",
    "                getattr(base_model, name).load_state_dict(weights)\n",
    "                print(f\"Successfully loaded weights into base_model.{name}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error loading weights for base_model.{name}: {e}. Not loaded.\")\n",
    "        else:\n",
    "            print(f\"No weights found for '{name}' in checkpoint.\")\n",
    "\n",
    "    # --- Load Gate weights (if applicable) ---\n",
    "    if base_model.fusion_mode == \"gated\":\n",
    "        if hasattr(base_model, 'gate'):\n",
    "            gate_weights = {k.replace(\"gate.\", \"\"): v for k, v in checkpoint.items() if k.startswith(\"gate.\")}\n",
    "            if gate_weights:\n",
    "                try:\n",
    "                    base_model.gate.load_state_dict(gate_weights)\n",
    "                    print(\"Successfully loaded weights into base_model.gate\")\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"Error loading weights for base_model.gate: {e}. Not loaded.\")\n",
    "            else:\n",
    "                print(\"No weights found for 'gate' in checkpoint.\")\n",
    "        else:\n",
    "            print(\"'gate' layer expected but not found in base_model. Skipping gate weight loading.\")\n",
    "\n",
    "\n",
    "model = CachedPINNWrapper(base_model).to(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8fd7e52-4638-4c9d-95b5-8b8e530f17aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** New best validation loss: 1.0840e-01 ***\n",
      "\n",
      "[Epoch 1/20] Train Loss: 6.8060e-02 | Data: 6.8060e-02 | PDE: 0.0000e+00 | CV-Reg: 0.0000e+00 | NE: 0.0000e+00\n",
      "| Val Loss: 1.0840e-01 (Data: 1.0840e-01, PDE: 0.0000e+00, CV-Reg: 0.0000e+00, NE: 0.0000e+00) | RE: 1.5062e+00 | Time: 10.99s\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Epoch 2/20] Train Loss: 2.3730e-03 | Data: 2.3730e-03 | PDE: 0.0000e+00 | CV-Reg: 0.0000e+00 | NE: 0.0000e+00\n",
      "| Val Loss: 1.7685e-01 (Data: 1.7685e-01, PDE: 0.0000e+00, CV-Reg: 0.0000e+00, NE: 0.0000e+00) | RE: 2.0604e+00 | Time: 10.29s\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x107d3d190>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cesarlindberg/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** New best validation loss: 5.2525e-02 ***\n",
      "\n",
      "[Epoch 3/20] Train Loss: 2.9104e-02 | Data: 2.9104e-02 | PDE: 0.0000e+00 | CV-Reg: 0.0000e+00 | NE: 0.0000e+00\n",
      "| Val Loss: 5.2525e-02 (Data: 5.2525e-02, PDE: 0.0000e+00, CV-Reg: 0.0000e+00, NE: 0.0000e+00) | RE: 6.9555e-01 | Time: 10.59s\n",
      "------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/cesarlindberg/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/cesarlindberg/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/cesarlindberg/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/multiprocessing/reductions.py\", line 112, in rebuild_tensor\n",
      "    t = torch._utils._rebuild_tensor(storage, storage_offset, size, stride)\n",
      "  File \"/Users/cesarlindberg/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/_utils.py\", line 174, in _rebuild_tensor\n",
      "    t = torch.empty((0,), dtype=storage.dtype, device=storage._untyped_storage.device)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 5) Train the PINNEX\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_loss, val_loss, data_loss, pde_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pinnex_minibatch_with_ecg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphysics_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormal_enforcement_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# New parameter\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_reg_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatches_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatches_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphys_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_every_n_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_every_n_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'cuda' if available\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollocation_points_filepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfine_heart_coll_pts_normals.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Exjobb/PINNEX_public/PINNEX/src/training/trainer_pinnex.py:510\u001b[0m, in \u001b[0;36mtrain_pinnex_minibatch_with_ecg\u001b[0;34m(wrapper, train_loader, val_loader, params, n_epochs, lr, weight_decay, physics_weight, cv_reg_weight, normal_enforcement_weight, batches_per_epoch, phys_batch_size, val_every_n_epochs, device, collocation_points_filepath)\u001b[0m\n\u001b[1;32m    505\u001b[0m lr_scheduler_state, lr_at_min \u001b[38;5;241m=\u001b[39m _update_lr_scheduler_state(\n\u001b[1;32m    506\u001b[0m     optimizer, avg_train_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m], lr_scheduler_state, min_lr_val\n\u001b[1;32m    507\u001b[0m )\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m val_every_n_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 510\u001b[0m     avg_val_losses \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheart_colloc_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_bds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphysics_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_reg_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_enforcement_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Pass NE weight\u001b[39;49;00m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphys_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_phys_each_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m     histories[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(avg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    517\u001b[0m     print_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m| Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpde\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, CV-Reg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_reg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, NE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mne\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m| RE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Exjobb/PINNEX_public/PINNEX/src/training/trainer_pinnex.py:345\u001b[0m, in \u001b[0;36m_validate_one_epoch\u001b[0;34m(wrapper, model, val_loader, params_general, device, heart_colloc_data, spatial_bounds, physics_weight, cv_reg_weight, normal_enforcement_weight, phys_batch_size, batches_per_epoch, sample_phys_each_epoch)\u001b[0m\n\u001b[1;32m    342\u001b[0m     effective_loader_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_loader), batches_per_epoch)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val_batch_idx, batch_val_content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m batches_per_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n_val_batches_processed \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m batches_per_epoch:\n\u001b[1;32m    347\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/utils/data/dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/utils/data/dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:342\u001b[0m, in \u001b[0;36mreduce_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    334\u001b[0m     torch\u001b[38;5;241m.\u001b[39msparse_coo,\n\u001b[1;32m    335\u001b[0m     torch\u001b[38;5;241m.\u001b[39msparse_csr,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    338\u001b[0m     torch\u001b[38;5;241m.\u001b[39msparse_bsc,\n\u001b[1;32m    339\u001b[0m }:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduce_sparse_tensor(tensor)\n\u001b[0;32m--> 342\u001b[0m storage \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_typed_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39m_untyped_storage\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    345\u001b[0m     (\n\u001b[1;32m    346\u001b[0m         device,\n\u001b[1;32m    347\u001b[0m         handle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m         event_sync_required,\n\u001b[1;32m    354\u001b[0m     ) \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39m_share_cuda_()\n",
      "File \u001b[0;32m~/anaconda3/envs/cardiac_pinn/lib/python3.9/site-packages/torch/_tensor.py:254\u001b[0m, in \u001b[0;36mTensor._typed_storage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_typed_storage\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    252\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muntyped_storage()\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m--> 254\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39muntyped_storage, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m, _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------\n",
    "# 5) Train the PINNEX\n",
    "# ---------------------------------------------\n",
    "train_loss, val_loss, data_loss, pde_loss = train_pinnex_minibatch_with_ecg(\n",
    "    wrapper=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    params=params,\n",
    "    n_epochs=n_epochs*2,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=1e-8,\n",
    "    physics_weight=0,\n",
    "    normal_enforcement_weight=0, # New parameter\n",
    "    cv_reg_weight=0,\n",
    "    batches_per_epoch=batches_per_epoch,\n",
    "    phys_batch_size=1024,\n",
    "    val_every_n_epochs=val_every_n_epochs,\n",
    "    device='cpu',  # or 'cuda' if available\n",
    "    collocation_points_filepath=\"fine_heart_coll_pts_normals.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009edae2-5825-40ef-9399-6968628c6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(train_loss) + 1)\n",
    "val_epochs = np.arange(val_every_n_epochs, len(train_loss) + 1, val_every_n_epochs)\n",
    "plt.figure(figsize=(10, 4))\n",
    "    \n",
    "# Plot Total Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.scatter(val_epochs, val_loss, color='red', label='Val Loss', zorder=3)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (log scale)\")\n",
    "plt.title(\"Total Loss vs. Epoch\")\n",
    "# Plot Data vs PDE Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, data_loss, label='Data Loss')\n",
    "plt.plot(epochs, pde_loss, label='PDE Residual Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (log scale)\")  \n",
    "plt.legend()\n",
    "plt.title(\"Data vs PDE Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b1c15-6d39-4273-aa5a-5596e6d7dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6980a-7a02-43c4-b461-57fc37044b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loss, val_loss, data_loss, pde_loss = train_lbfgs_with_ecg(model,\n",
    "                         train_loader,\n",
    "                         val_loader,\n",
    "                         n_epochs=5,\n",
    "                         lr=1e-3,\n",
    "                         physics_weight=physics_weight,\n",
    "                         device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7084a6-9840-4711-a23e-a1edfa1a4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x-axis values\n",
    "epochs = np.arange(1, len(train_loss) + 1)\n",
    "val_every_n_epochs = 1  # update this if different\n",
    "val_epochs = np.arange(val_every_n_epochs, len(train_loss) + 1, val_every_n_epochs)\n",
    "\n",
    "# Trim val_loss to match number of validation points\n",
    "val_loss_trimmed = val_loss[:len(val_epochs)]\n",
    "\n",
    "# Create plots\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot Total Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.scatter(val_epochs, val_loss_trimmed, color='red', label='Val Loss', zorder=3)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (log scale)\")\n",
    "plt.title(\"Total Loss vs. Epoch\")\n",
    "\n",
    "# Plot Data vs PDE Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, data_loss, label='Data Loss')\n",
    "plt.plot(epochs, pde_loss, label='PDE Residual Loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (log scale)\")\n",
    "plt.legend()\n",
    "plt.title(\"Data vs PDE Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87637b02-4cf6-46b9-b44c-ccded0c9412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Evaluation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Evaluate model on validation set\n",
    "true_T, pred_T, pred_c = evaluate_pinnex(model, val_loader, device)\n",
    "\n",
    "# Compute metrics for activation time T\n",
    "re_T, mse_T, cc_T = compute_metrics(true_T, pred_T)\n",
    "\n",
    "# Print results\n",
    "print(\"------ Evaluation Results ------\")\n",
    "print(f\"Relative Error (RE) for T: {re_T:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE) for T: {mse_T:.4f}\")\n",
    "print(f\"Correlation Coefficient (CC) for T: {cc_T:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc7cae-3650-4211-b586-69a45c2a57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"models/eik_testing.pth\")\n",
    "# TO LOAD\n",
    "#model.load_state_dict(torch.load(\"pinn_mod1.pth\"))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "36bda6d1-6b9d-4ca9-9d38-b106de738ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PINN-ECG prediction process...\n",
      "Reading block.pts file: ../data/synthetic/raw/heart_1200.pts...\n",
      "Loaded 207079 spatial points.\n",
      "Loading ECG data for sim_id 1000 from ../data/synthetic/parsed/ecg_case0004.parquet...\n",
      "Loaded ECG data with shape torch.Size([12, 200]).\n",
      "Streaming spatial data and running inference...\n",
      "Prediction process completed. Results written to case0004_predby_123fib_phys.dat\n",
      "Creating IGB file with command: igbhead -x207079 -y1 -z1 -t1 -dfloat -slittle -X1.3856e-05 -Y1 -Z1 -T100 -I1.91988e-10 -J1 -K1 -L1 -S1 -1\"um\" -2\"um\" -3\"um\" -4\"ms\" --create -fcase0004_predby_123fib_phys.igb case0004_predby_123fib_phys.dat\n",
      "Successfully created IGB file: case0004_predby_123fib_phys.igb\n",
      "Temporary prediction file case0004_predby_123fib_phys.dat removed.\n",
      "Process complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adjusting dim_x to make dimensions consistent\n",
      "Adjusting dim_y to make dimensions consistent\n",
      "Adjusting dim_t to make dimensions consistent\n"
     ]
    }
   ],
   "source": [
    "from src.utils.igb_utils import write_pinnex_predictions_streamed\n",
    "\n",
    "write_pinnex_predictions_streamed(base_model, \n",
    "                                  block_pts_file=\"../data/synthetic/raw/heart_1200.pts\", \n",
    "                                  ecg_parquet_file=\"../data/synthetic/parsed/ecg_case0004.parquet\",\n",
    "                                  sim_id=1000,\n",
    "                                  filename='case0004_predby_123fib_phys.dat', \n",
    "                                  CV=False\n",
    "                                 )\n",
    "                          \n",
    "#igbhead -x11767 -y1 -z1 -t5001 -dfloat --create -f vm_phys.igb predictions_PINN.txt to convert to igb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "bb17b574-5c0a-46b7-b233-d6f0f5d73c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "4e4be164-8403-4547-b3a7-f3c24067a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation: heart_1fib_phys | Healthy Parquet ID: 16 ---\n",
      "Loaded delay file with 44 lines.\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 180\n",
      "  Diff Metrics - PCC: 0.9885, CosineSim(Diff): 0.9853\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9981\n",
      "progress: 1/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 181\n",
      "  Diff Metrics - PCC: 0.9893, CosineSim(Diff): 0.9837\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9967\n",
      "progress: 2/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 182\n",
      "  Diff Metrics - PCC: 0.9824, CosineSim(Diff): 0.9724\n",
      "  Direct Fibrotic PCC: 0.9997\n",
      "  Direct Fibrotic CosineSim: 0.9998\n",
      "progress: 3/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 183\n",
      "  Diff Metrics - PCC: 0.9824, CosineSim(Diff): 0.9685\n",
      "  Direct Fibrotic PCC: 0.9997\n",
      "  Direct Fibrotic CosineSim: 0.9998\n",
      "progress: 4/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 114\n",
      "  Diff Metrics - PCC: 0.9915, CosineSim(Diff): 0.9924\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9990\n",
      "progress: 5/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 115\n",
      "  Diff Metrics - PCC: 0.9868, CosineSim(Diff): 0.9754\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9999\n",
      "progress: 6/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 116\n",
      "  Diff Metrics - PCC: 0.9892, CosineSim(Diff): 0.9381\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9969\n",
      "progress: 7/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 117\n",
      "  Diff Metrics - PCC: 0.9897, CosineSim(Diff): 0.9686\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9985\n",
      "progress: 8/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 168\n",
      "  Diff Metrics - PCC: 0.9812, CosineSim(Diff): 0.9604\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9997\n",
      "progress: 9/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 169\n",
      "  Diff Metrics - PCC: 0.9804, CosineSim(Diff): 0.9793\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9991\n",
      "progress: 10/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 160\n",
      "  Diff Metrics - PCC: 0.9349, CosineSim(Diff): 0.9314\n",
      "  Direct Fibrotic PCC: 0.9990\n",
      "  Direct Fibrotic CosineSim: 0.9967\n",
      "progress: 11/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 161\n",
      "  Diff Metrics - PCC: 0.9838, CosineSim(Diff): 0.9811\n",
      "  Direct Fibrotic PCC: 0.9997\n",
      "  Direct Fibrotic CosineSim: 0.9999\n",
      "progress: 12/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 172\n",
      "  Diff Metrics - PCC: 0.9621, CosineSim(Diff): 0.9649\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9975\n",
      "progress: 13/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 173\n",
      "  Diff Metrics - PCC: 0.9571, CosineSim(Diff): 0.9601\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9982\n",
      "progress: 14/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 174\n",
      "  Diff Metrics - PCC: 0.9623, CosineSim(Diff): 0.9561\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9999\n",
      "progress: 15/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 175\n",
      "  Diff Metrics - PCC: 0.9516, CosineSim(Diff): 0.9403\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9986\n",
      "progress: 16/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 100\n",
      "  Diff Metrics - PCC: 0.9741, CosineSim(Diff): 0.9727\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9998\n",
      "progress: 17/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 101\n",
      "  Diff Metrics - PCC: 0.9681, CosineSim(Diff): 0.9561\n",
      "  Direct Fibrotic PCC: 0.9997\n",
      "  Direct Fibrotic CosineSim: 0.9989\n",
      "progress: 18/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 102\n",
      "  Diff Metrics - PCC: 0.9792, CosineSim(Diff): 0.9637\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9973\n",
      "progress: 19/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 103\n",
      "  Diff Metrics - PCC: 0.9682, CosineSim(Diff): 0.9722\n",
      "  Direct Fibrotic PCC: 0.9996\n",
      "  Direct Fibrotic CosineSim: 0.9999\n",
      "progress: 20/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 194\n",
      "  Diff Metrics - PCC: 0.8763, CosineSim(Diff): 0.7570\n",
      "  Direct Fibrotic PCC: 0.9986\n",
      "  Direct Fibrotic CosineSim: 0.9993\n",
      "progress: 21/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 195\n",
      "  Diff Metrics - PCC: 0.8870, CosineSim(Diff): 0.7408\n",
      "  Direct Fibrotic PCC: 0.9988\n",
      "  Direct Fibrotic CosineSim: 0.9986\n",
      "progress: 22/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 196\n",
      "  Diff Metrics - PCC: 0.8824, CosineSim(Diff): 0.6834\n",
      "  Direct Fibrotic PCC: 0.9988\n",
      "  Direct Fibrotic CosineSim: 0.9988\n",
      "progress: 23/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 197\n",
      "  Diff Metrics - PCC: 0.8999, CosineSim(Diff): 0.8014\n",
      "  Direct Fibrotic PCC: 0.9989\n",
      "  Direct Fibrotic CosineSim: 0.9966\n",
      "progress: 24/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 158\n",
      "  Diff Metrics - PCC: 0.9232, CosineSim(Diff): 0.9251\n",
      "  Direct Fibrotic PCC: 0.9992\n",
      "  Direct Fibrotic CosineSim: 0.9973\n",
      "progress: 25/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 159\n",
      "  Diff Metrics - PCC: 0.9369, CosineSim(Diff): 0.9071\n",
      "  Direct Fibrotic PCC: 0.9993\n",
      "  Direct Fibrotic CosineSim: 0.9988\n",
      "progress: 26/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 150\n",
      "  Diff Metrics - PCC: 0.9416, CosineSim(Diff): 0.9048\n",
      "  Direct Fibrotic PCC: 0.9994\n",
      "  Direct Fibrotic CosineSim: 0.9967\n",
      "progress: 27/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 151\n",
      "  Diff Metrics - PCC: 0.9310, CosineSim(Diff): 0.9405\n",
      "  Direct Fibrotic PCC: 0.9993\n",
      "  Direct Fibrotic CosineSim: 0.9998\n",
      "progress: 28/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 122\n",
      "  Diff Metrics - PCC: 0.9662, CosineSim(Diff): 0.9763\n",
      "  Direct Fibrotic PCC: 0.9995\n",
      "  Direct Fibrotic CosineSim: 0.9990\n",
      "progress: 29/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 123\n",
      "  Diff Metrics - PCC: 0.9587, CosineSim(Diff): 0.9734\n",
      "  Direct Fibrotic PCC: 0.9994\n",
      "  Direct Fibrotic CosineSim: 0.9966\n",
      "progress: 30/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 124\n",
      "  Diff Metrics - PCC: 0.9643, CosineSim(Diff): 0.9736\n",
      "  Direct Fibrotic PCC: 0.9995\n",
      "  Direct Fibrotic CosineSim: 0.9995\n",
      "progress: 31/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 125\n",
      "  Diff Metrics - PCC: 0.9715, CosineSim(Diff): 0.9783\n",
      "  Direct Fibrotic PCC: 0.9995\n",
      "  Direct Fibrotic CosineSim: 0.9973\n",
      "progress: 32/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 136\n",
      "  Diff Metrics - PCC: 0.9919, CosineSim(Diff): 0.9726\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9995\n",
      "progress: 33/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 137\n",
      "  Diff Metrics - PCC: 0.9880, CosineSim(Diff): 0.9816\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9964\n",
      "progress: 34/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 138\n",
      "  Diff Metrics - PCC: 0.9909, CosineSim(Diff): 0.9846\n",
      "  Direct Fibrotic PCC: 0.9997\n",
      "  Direct Fibrotic CosineSim: 0.9996\n",
      "progress: 35/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 139\n",
      "  Diff Metrics - PCC: 0.9901, CosineSim(Diff): 0.9409\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9985\n",
      "progress: 36/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 140\n",
      "  Diff Metrics - PCC: 0.9953, CosineSim(Diff): 0.9952\n",
      "  Direct Fibrotic PCC: 0.9999\n",
      "  Direct Fibrotic CosineSim: 0.9979\n",
      "progress: 37/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 141\n",
      "  Diff Metrics - PCC: 0.9929, CosineSim(Diff): 0.9908\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9989\n",
      "progress: 38/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 142\n",
      "  Diff Metrics - PCC: 0.9953, CosineSim(Diff): 0.9945\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9975\n",
      "progress: 39/40\n",
      "\n",
      "Processing FIBROTIC: Parquet ID 143\n",
      "  Diff Metrics - PCC: 0.9935, CosineSim(Diff): 0.9887\n",
      "  Direct Fibrotic PCC: 0.9998\n",
      "  Direct Fibrotic CosineSim: 0.9996\n",
      "progress: 40/40\n",
      "\n",
      "--- Averaged Results ---\n",
      "avg_diff_pcc: 0.9645\n",
      "avg_diff_cosine: 0.9433\n",
      "avg_direct_fib_pcc: 0.9995\n",
      "avg_direct_fib_cosine: 0.9985\n",
      "--- Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from notebooks.evaluation.evaluation_pipeline import evaluate_fibrosis_detection\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pinn_model_for_evaluation = base_model # <<--- REPLACE THIS WITH YOUR LOADED MODEL INSTANCE\n",
    "\n",
    "# 2. Define paths (use absolute paths for robustness)\n",
    "notebook_base_dir = os.getcwd() # Assumes notebook is in 'notebooks/'\n",
    "\n",
    "healthy_parquet_sim_id = 16 # Integer or string, e.g., from your example 1000, 10, etc.\n",
    "\n",
    "# Paths relative to the NOTEBOOK'S location\n",
    "folder = \"heart_1fib\"\n",
    "ecg_file_rel = \"evaluation/\" + folder + \"/ecg_all.parquet\" # ADJUST\n",
    "pts_file_rel = \"evaluation/\" + folder + \"/heart.pts\" # ADJUST - ensure this is the correct .pts for your sims\n",
    "delay_file_rel = \"evaluation/\" + folder + \"/delays.txt\"\n",
    "sim_raw_dir_rel = \"evaluation/\" + folder # ADJUST\n",
    "\n",
    "ecg_parquet_abs = os.path.abspath(os.path.join(notebook_base_dir, ecg_file_rel))\n",
    "block_pts_abs = os.path.abspath(os.path.join(notebook_base_dir, pts_file_rel))\n",
    "delay_file_abs = os.path.abspath(os.path.join(notebook_base_dir, delay_file_rel))\n",
    "sim_raw_base_abs = os.path.abspath(os.path.join(notebook_base_dir, sim_raw_dir_rel))\n",
    "\n",
    "model_tag_name = \"heart_1fib_phys\" # For naming output files\n",
    "\n",
    "# 3. Run the evaluation\n",
    "# Ensure 'pinn_model_for_evaluation' is your loaded and ready-to-use model object\n",
    "if pinn_model_for_evaluation is not None: # Check if model loaded\n",
    "    evaluation_results[model_tag_name] = evaluate_fibrosis_detection(\n",
    "        model=pinn_model_for_evaluation,\n",
    "        healthy_parquet_sim_id=healthy_parquet_sim_id,\n",
    "        ecg_parquet_file_abs_path=ecg_parquet_abs,\n",
    "        block_pts_file_abs_path=block_pts_abs,\n",
    "        delay_file_abs_path=delay_file_abs,\n",
    "        sim_raw_base_abs_path=sim_raw_base_abs,\n",
    "        model_name_tag=model_tag_name,\n",
    "        CV_predictions=False,  # Set to True if your model output for 'T_pred' should come from 'c_pred'\n",
    "        prediction_batch_size=1024,\n",
    "        force_regenerate_predictions=False, # Set to True if you modified the model or want fresh predictions\n",
    "        force_regenerate_diffs=False      # Set to True if you want to re-calculate IGB differences\n",
    "    )\n",
    "else:\n",
    "    print(\"Model not loaded. Please load your model before running evaluation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "46a7d5fb-fe64-4441-8444-4be31cb9549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "--- Averaged Results ---\n",
      "avg_diff_pcc: 0.5678\n",
      "avg_diff_cosine: 0.7547\n",
      "avg_direct_fib_pcc: 0.9888\n",
      "avg_direct_fib_cosine: 0.9968\n",
      "--- Evaluation Complete ---\n"
     ]
    }
   ],
   "source": [
    "results = evaluation_results[\"heart_123fib_phys\"]\n",
    "sim_ids = results[\"fibrotic_parquet_sim_ids\"]\n",
    "individual_diff_pcc = results[\"individual_diff_pcc\"]\n",
    "individual_diff_cosine = results[\"individual_diff_cosine\"]\n",
    "individual_direct_fib_pcc = results[\"individual_direct_fib_pcc\"]\n",
    "individual_direct_fib_cosine = results[\"individual_direct_fib_cosine\"]\n",
    "\n",
    "\n",
    "# Initialize accumulators and counter\n",
    "total_diff_pcc = 0\n",
    "total_diff_cosine = 0\n",
    "total_direct_fib_pcc = 0\n",
    "total_direct_fib_cosine = 0\n",
    "count = 0\n",
    "\n",
    "# Loop through sim_ids and accumulate metrics for sim_id < 199\n",
    "for i in range(len(sim_ids)):\n",
    "    sim_id = int(sim_ids[i])\n",
    "    \n",
    "    if int(str(sim_id)[0]) != 3:\n",
    "        continue\n",
    "\n",
    "        \n",
    "    total_diff_pcc += individual_diff_pcc[i]\n",
    "    total_diff_cosine += individual_diff_cosine[i]\n",
    "    total_direct_fib_pcc += individual_direct_fib_pcc[i]\n",
    "    total_direct_fib_cosine += individual_direct_fib_cosine[i]\n",
    "    count += 1\n",
    "print(count)\n",
    "# Calculate averages\n",
    "avg_diff_pcc = total_diff_pcc / count\n",
    "avg_diff_cosine = total_diff_cosine / count\n",
    "avg_direct_fib_pcc = total_direct_fib_pcc / count\n",
    "avg_direct_fib_cosine = total_direct_fib_cosine / count\n",
    "\n",
    "# Print results\n",
    "print(\"--- Averaged Results ---\")\n",
    "print(f\"avg_diff_pcc: {avg_diff_pcc:.4f}\")\n",
    "print(f\"avg_diff_cosine: {avg_diff_cosine:.4f}\")\n",
    "print(f\"avg_direct_fib_pcc: {avg_direct_fib_pcc:.4f}\")\n",
    "print(f\"avg_direct_fib_cosine: {avg_direct_fib_cosine:.4f}\")\n",
    "print(\"--- Evaluation Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "716e972e-4097-4685-84b2-092d9a7286a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individual_diff_pcc:   = +0.097  95 % CI = (+0.035, +0.159)  p_t = 0.0031  p_w = 0.00369\n",
      "individual_diff_cosine:   = +0.177  95 % CI = (+0.121, +0.233)  p_t = 2.043e-07  p_w = 1.162e-06\n",
      "individual_direct_fib_pcc:   = +0.126  95 % CI = (+0.075, +0.176)  p_t = 1.246e-05  p_w = 5.846e-05\n",
      "individual_direct_fib_cosine:   = +0.025  95 % CI = (+0.010, +0.039)  p_t = 0.001302  p_w = 0.0002806\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def fisher_z(r):\n",
    "    \"\"\"Clip to open interval (-1,1) to avoid inf, then Fisher transform.\"\"\"\n",
    "    return np.arctanh(np.clip(r, -0.999999, 0.999999))\n",
    "\n",
    "def paired_ci_and_test(modelA_vals, modelB_vals, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Paired comparison of two models tested on the *same* samples.\n",
    "\n",
    "    Returns:\n",
    "        mean_diff_r : mean(B  A) on the original r scale\n",
    "        ci_r        : tuple (low, high) CI on r scale\n",
    "        p_t         : p-value from paired t-test\n",
    "        p_wilcoxon  : p-value from Wilcoxon signed-rank (non-parametric)\n",
    "    \"\"\"\n",
    "    a = np.asarray(modelA_vals, dtype=float)\n",
    "    b = np.asarray(modelB_vals, dtype=float)\n",
    "\n",
    "    # Drop pairs where either value is nan\n",
    "    mask = ~np.isnan(a) & ~np.isnan(b)\n",
    "    a, b = a[mask], b[mask]\n",
    "    if len(a) < 2:\n",
    "        return np.nan, (np.nan, np.nan), np.nan, np.nan\n",
    "\n",
    "    # Fisher transform\n",
    "    z_a, z_b = fisher_z(a), fisher_z(b)\n",
    "    diff_z   = z_b - z_a\n",
    "\n",
    "    # Mean & CI on z\n",
    "    mean_z   = diff_z.mean()\n",
    "    sem_z    = stats.sem(diff_z)\n",
    "    df       = len(diff_z) - 1\n",
    "    t_crit   = stats.t.ppf(1 - alpha/2, df)\n",
    "    ci_z = (mean_z - t_crit * sem_z, mean_z + t_crit * sem_z)\n",
    "\n",
    "    # Back-transform CI and mean to r scale (addend interpretation)\n",
    "    mean_r  = np.tanh(mean_z)\n",
    "    ci_r    = tuple(np.tanh(ci_z))\n",
    "\n",
    "    # Significance tests\n",
    "    t_stat, p_t        = stats.ttest_rel(z_b, z_a)   # works in z too\n",
    "    w_stat, p_wilcoxon = stats.wilcoxon(diff_z)      # signed-rank\n",
    "\n",
    "    return mean_r, ci_r, p_t, p_wilcoxon\n",
    "    \n",
    "name = \"heart_1fib\"\n",
    "res_A = evaluation_results[name]\n",
    "res_B = evaluation_results[name + \"_phys\"]\n",
    "metrics = [\"individual_diff_pcc\",\n",
    "           \"individual_diff_cosine\",\n",
    "           \"individual_direct_fib_pcc\",\n",
    "           \"individual_direct_fib_cosine\"]\n",
    "\n",
    "for m in metrics:\n",
    "    mean_gain, ci_gain, p_t, p_w = paired_ci_and_test(res_A[m], res_B[m])\n",
    "    print(f\"{m}:   = {mean_gain:+.3f}  \"\n",
    "          f\"95 % CI = ({ci_gain[0]:+.3f}, {ci_gain[1]:+.3f})  \"\n",
    "          f\"p_t = {p_t:.4g}  p_w = {p_w:.4g}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4990495-0bcf-4e63-9cc5-46ceb1cf7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Count parameters for each component\n",
    "pde_encoder_params = count_parameters(base_model.pde_encoder)\n",
    "ecg_encoder_params = count_parameters(base_model.ecg_encoder)\n",
    "\n",
    "print(f\"PDE Encoder Parameters: {pde_encoder_params}\")\n",
    "print(f\"ECG Encoder Parameters: {ecg_encoder_params}\")\n",
    "print(f\"Total Model Parameters: {pde_encoder_params + ecg_encoder_params}\")\n",
    "\n",
    "# Print the model's weights\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name} | Size: {param.size()}) # | Values: \\n{param.data}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
